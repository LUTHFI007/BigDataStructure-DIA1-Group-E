# BigDataStructure-DIA1-Group-E

**Big Data Infrastructure and Cloud â€“ ESILV A5**  

## ğŸ¯ Project Overview

This project implements a **NoSQL database simulator** to study the impact of **data model denormalization** on:
- Storage size (GB/TB/PB)
- Sharding efficiency (over 1,000 servers)
- Query performance & costs (time, carbon footprint, monetary price)

We simulate **5 different denormalized designs** (DB1 to DB5) for an online store with:
- 10 million clients
- 100,000 products
- 4.1 billion order lines
- Average 41,000 order lines per product

The simulator is built in Python and fully automates size calculation, sharding simulation, filter/join/aggregate queries, and final model selection.

**Final conclusion (Chapter 5)**:  
**DB1** is the best model â€” lowest total cost, balanced sharding, realistic scalability, no extreme duplication.  
DB4 and DB5 are impractical due to massive storage explosion.

## ğŸ‘¥ Team Members

| Name                              | Role / Contribution                     |
|-----------------------------------|-----------------------------------------|
| Yasar Thajudeen                   | JSON Schema design & testing            |
| Luthfi Juneeda Shaj               | Size computation & sharding logic       |
| Sethulakshmi Kochuchirayil Babu   | Query simulation & cost estimation      |
| Man Vijaybai Patel                | Integration, testing & documentation    |

## ğŸ“Š Key Statistics

| Entity        | Count          | Notes                                      |
|---------------|----------------|--------------------------------------------|
| Clients       | 10,000,000     | Each makes ~100 orders                     |
| Products      | 100,000        | 5,000 brands, avg 2 categories             |
| Order Lines   | 4,100,000,000  | Avg 41,000 lines per product               |
| Warehouses    | 200            |                                            |
| Stock entries | 20,000,000     | Even distribution across warehouses        |

## ğŸ“ Field Size Assumptions 

| Type          | Size (bytes) | Overhead per field |
|---------------|--------------|--------------------|
| Integer/Number| 8            | +12                |
| String        | 80           | +12                |
| Date          | 20           | +12                |
| Long String   | 200          | +12                |

## ğŸ—‚ï¸ Project Structure

```text
BigDataStructure-DIA1-Group-E/
â”œâ”€â”€ main.py                 # Core simulator: size calculation & sharding
â”œâ”€â”€ test.py                 # Runs Chapter 2 analysis + Ch.3 & Ch.4 demos
â”œâ”€â”€ query_sim.py            # Chapter 3: Filter & Join queries + costs
â”œâ”€â”€ aggregate_sim.py        # Chapter 4: Aggregate queries + costs
â”œâ”€â”€ run_final.py            # Chapter 5: Full challenge â€“ all queries on 5 models
â”œâ”€â”€ README.md               # This file â€“ full project documentation
â”œâ”€â”€ stats.json              # Real statistics (cardinality, avg, distinct)
â””â”€â”€ schemas/                # 5 denormalized JSON schemas (DB1â€“DB5)
    â”œâ”€â”€ db1.json
    â”œâ”€â”€ db2.json
    â”œâ”€â”€ db3.json
    â”œâ”€â”€ db4.json
    â””â”€â”€ db5.json
```

## ğŸš€ How to Run

1. Prerequisites
   - Python 3.8+
   - No external packages needed

2. Run Chapter 2 analysis + Ch.3 & Ch.4 demos

```
python test.py
```

3. Run final Chapter 5 challenge (full use case on all models)

```
python run_final.py
```